# kinfra + kworktree: Architecture

## Overview

The system adds a Python CLI (`kinfra`) and a skill (`kworktree`) to devops-ai. The CLI handles all deterministic operations: worktree lifecycle, sandbox slot allocation, compose override generation, health gating, shared observability management, and optional agent-deck session management. Projects declare their infrastructure via `.devops-ai/infra.toml`, generated by `kinfra init` which also parameterizes the project's `docker-compose.yml` for port isolation.

The architecture has four layers:

1. **Generic infrastructure** — kinfra CLI in devops-ai (worktrees, slots, ports, health, observability)
2. **Project adapter** — infra.toml + parameterized compose file (project-specific services, ports, mounts)
3. **Shared observability** — always-running Jaeger + Grafana + Prometheus on dedicated ports
4. **Orchestration** — kworktree skill for AI coding tools (conversational wrapper around kinfra)

## Component Diagram

```
┌─────────────────────────────────────────────────────────────────┐
│  AI Coding Tool (Claude Code / Codex / Copilot)                 │
│  ┌───────────────────────────────┐                              │
│  │  /kworktree skill             │  Conversational interface    │
│  │  (skills/kworktree/SKILL.md)  │  Wraps kinfra commands       │
│  └──────────┬────────────────────┘                              │
└─────────────┼───────────────────────────────────────────────────┘
              │ Bash calls
              ▼
┌─────────────────────────────────────────────────────────────────┐
│  kinfra CLI  (Python / Typer)                                   │
│                                                                 │
│  Commands:                                                      │
│  ┌──────┐ ┌──────┐ ┌──────┐ ┌──────┐ ┌───────────┐ ┌────────┐ │
│  │ init │ │ spec │ │ impl │ │ done │ │ worktrees │ │ status │ │
│  └──┬───┘ └──┬───┘ └──┬───┘ └──┬───┘ └─────┬─────┘ └───┬────┘ │
│     │        │        │        │            │           │      │
│  Modules:    │        │        │            │           │      │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │                                                          │  │
│  │  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐ │  │
│  │  │ Config   │  │ Worktree │  │   Slot   │  │ Sandbox  │ │  │
│  │  │ Loader   │  │ Manager  │  │ Registry │  │ Manager  │ │  │
│  │  └──────────┘  └──────────┘  └────┬─────┘  └────┬─────┘ │  │
│  │                                   │             │        │  │
│  │                ┌──────────┐  ┌────┴─────┐  ┌────┴─────┐  │  │
│  │                │Observ-   │  │  Port    │  │ Override │  │  │
│  │                │ability   │  │Allocator │  │Generator │  │  │
│  │                │Manager   │  │  + TCP   │  │ + Health │  │  │
│  │                │          │  │  Check   │  │   Gate   │  │  │
│  │                └──────────┘  └──────────┘  └──────────┘  │  │
│  │                                                          │  │
│  │  ┌──────────────────────────────────────────────────────┐│  │
│  │  │  Agent-Deck Integration (optional)                   ││  │
│  │  └──────────────────────────────────────────────────────┘│  │
│  └──────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────────┘
              │                     │                │
              ▼                     ▼                ▼
┌────────────────────┐ ┌─────────────────────┐ ┌──────────────────┐
│  Global State      │ │  Project Files      │ │ Shared Observ.   │
│                    │ │                     │ │                  │
│  ~/.devops-ai/     │ │  project/           │ │ ~/.devops-ai/    │
│    registry.json   │ │    .devops-ai/      │ │   observability/ │
│    slots/          │ │      infra.toml     │ │   docker-compose │
│      <proj>-<N>/   │ │    docker-compose   │ │   .yml           │
│        .env.sandbox│ │      .yml           │ │                  │
│        override.yml│ │                     │ │ Jaeger + Grafana │
└────────────────────┘ └─────────────────────┘ │ + Prometheus     │
                                               └──────────────────┘
```

### Component Relationships (Structured Summary)

| Component | Type | Depends On | Used By |
|-----------|------|------------|---------|
| kworktree skill | Markdown prompt | kinfra CLI | AI coding tools |
| kinfra CLI | Python/Typer entry point | Config Loader | kworktree skill, developer terminal |
| Config Loader | Module | infra.toml file | All CLI commands |
| Worktree Manager | Module | Git, Config Loader | `spec`, `impl`, `done` commands |
| Slot Registry | Module | registry.json | `impl`, `done`, `status`, `worktrees` commands |
| Port Allocator | Module | Slot Registry, Config Loader | Slot Registry |
| Sandbox Manager | Module | Docker Compose, Config Loader, Observability Manager | `impl`, `done` commands |
| Override Generator | Sub-module of Sandbox Manager | Config Loader, Observability Manager | Sandbox Manager |
| Health Gate | Sub-module of Sandbox Manager | Config Loader | Sandbox Manager |
| Observability Manager | Module | Docker Compose, observability template | `init`, `impl`, `observability` commands |
| Agent-Deck Integration | Module (optional) | `agent-deck` binary on PATH | `impl`, `done` commands |

## Components

### Config Loader

**Location:** `src/devops_ai/config.py`
**Purpose:** Reads and validates `.devops-ai/infra.toml` from the project root. Provides typed access to all configuration values.

**Interface (illustrative):**
```python
@dataclass
class ServicePort:
    env_var: str        # e.g., "KHEALTH_API_PORT"
    base_port: int      # e.g., 8080

@dataclass
class InfraConfig:
    project_name: str
    prefix: str                          # worktree naming prefix
    compose_file: str                    # path to docker-compose file
    ports: list[ServicePort]             # port mappings to offset
    health_endpoint: str | None          # e.g., "/api/v1/health"
    health_port_var: str | None          # which env var has the health port
    health_timeout: int                  # seconds, default 60
    code_mounts: list[str]               # dirs from worktree to mount
    code_mount_targets: list[str]        # compose services receiving code mounts
    shared_mounts: list[str]             # dirs from main repo (not worktree)
    shared_mount_targets: list[str]      # compose services receiving shared mounts

def load_config(project_root: Path) -> InfraConfig: ...
def find_project_root() -> Path: ...     # walk up looking for .devops-ai/
```

### Worktree Manager

**Location:** `src/devops_ai/worktree.py`
**Purpose:** Creates and removes git worktrees with consistent naming conventions. Checks for dirty state before removal.

**Interface (illustrative):**
```python
def create_spec_worktree(feature: str, config: InfraConfig) -> Path: ...
def create_impl_worktree(feature: str, milestone: str, config: InfraConfig) -> Path: ...
def remove_worktree(path: Path, force: bool = False) -> None: ...
def list_worktrees(config: InfraConfig) -> list[WorktreeInfo]: ...
def check_dirty(path: Path) -> DirtyState: ...
```

**Naming conventions:**
- Spec: `../<prefix>-spec-<feature>/` on branch `spec/<feature>`
- Impl: `../<prefix>-impl-<feature>-<milestone>/` on branch `impl/<feature>-<milestone>`

### Slot Registry

**Location:** `src/devops_ai/registry.py`
**Purpose:** Global slot tracking across all projects. Assigns unique slot IDs to prevent port conflicts. Persists state in `~/.devops-ai/registry.json`.

**State file:** `~/.devops-ai/registry.json`

**Interface (illustrative):**
```python
@dataclass
class SlotInfo:
    slot_id: int
    project: str              # project name from infra.toml
    worktree_path: str        # absolute path to worktree
    slot_dir: str             # absolute path to slot directory
    ports: dict[str, int]     # env_var -> actual_port (base + slot_id)
    claimed_at: str           # ISO timestamp
    status: str               # "running" | "stopped"

@dataclass
class Registry:
    version: int
    slots: dict[int, SlotInfo]    # slot_id -> info (only claimed slots)

def load_registry() -> Registry: ...
def save_registry(registry: Registry) -> None: ...
def allocate_slot(registry: Registry, config: InfraConfig) -> int: ...
def claim_slot(registry: Registry, slot_id: int, project: str,
               worktree_path: Path, ports: dict[str, int]) -> SlotInfo: ...
def release_slot(registry: Registry, slot_id: int) -> None: ...
def get_slot_for_worktree(registry: Registry, path: Path) -> SlotInfo | None: ...
```

**Slot allocation algorithm:**
1. Iterate slot IDs 1-100
2. Skip already-claimed IDs
3. Compute ports for candidate slot: `base + slot_id` for each port
4. TCP bind test all candidate ports
5. If all available: return slot ID
6. If any port in use: skip to next candidate
7. If no slot found: error

### Port Allocator

**Location:** `src/devops_ai/ports.py`
**Purpose:** Computes port offsets and checks for availability via TCP bind test.

**Interface (illustrative):**
```python
def compute_ports(config: InfraConfig, slot_id: int) -> dict[str, int]: ...
def check_ports_available(ports: dict[str, int]) -> list[PortConflict]: ...
def check_base_port_safety(config: InfraConfig, registry: Registry) -> list[str]: ...
```

**Port formula:** `actual_port = base_port + slot_id`

**Conflict detection layers:**
1. **Static (registry):** Check no other claimed slot uses the same ports
2. **Dynamic (TCP bind):** Attempt to bind each port briefly — catches conflicts with non-kinfra processes (including ktrdr's own sandboxes)

### Sandbox Manager

**Location:** `src/devops_ai/sandbox.py`
**Purpose:** Manages Docker Compose lifecycle for sandbox slots. Generates env files, override files, starts/stops containers, runs health checks.

**Interface (illustrative):**
```python
def create_slot_dir(project: str, slot_id: int) -> Path: ...
def remove_slot_dir(slot_dir: Path) -> None: ...
def generate_env_file(config: InfraConfig, slot: SlotInfo) -> Path: ...
def generate_override(config: InfraConfig, slot: SlotInfo,
                      worktree_path: Path, main_repo_path: Path) -> Path: ...
def start_sandbox(config: InfraConfig, slot: SlotInfo, worktree_path: Path) -> None: ...
def stop_sandbox(slot: SlotInfo, worktree_path: Path) -> None: ...
def run_health_gate(config: InfraConfig, slot: SlotInfo) -> bool: ...
```

**Slot directory:** `~/.devops-ai/slots/<project>-<slot_id>/`

Contains:
- `.env.sandbox` — environment variables for port mappings and COMPOSE_PROJECT_NAME
- `docker-compose.override.yml` — code mounts, shared mounts, observability network

**Docker compose invocation:**
```bash
docker compose \
  -f <worktree>/docker-compose.yml \
  -f <slot_dir>/docker-compose.override.yml \
  --env-file <slot_dir>/.env.sandbox \
  up -d
```

Key: compose file comes from the **worktree** (so feature-branch compose changes are reflected), while override and env come from the **slot directory** (infrastructure state separate from code).

### Override Generator (sub-module of Sandbox Manager)

**Purpose:** Generates `docker-compose.override.yml` that connects a worktree's code to a sandbox slot and joins the shared observability network.

**Generated override structure:**
```yaml
# Generated by kinfra impl — do not edit manually
# Worktree: /path/to/worktree
# Slot: <project>-<slot_id>
# Generated at: <timestamp>

networks:
  devops-ai-observability:
    external: true

services:
  <service>:
    networks:
      - default
      - devops-ai-observability
    environment:
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://devops-ai-jaeger:4317
      - OTEL_RESOURCE_ATTRIBUTES=service.namespace=<project>-slot-<slot_id>
    volumes:
      - <worktree_path>/<code_dir>:<container_path>
      # ... more code mounts
      - <main_repo_path>/<shared_dir>:<container_path>
      # ... more shared mounts
```

The override adds three things:
1. **Observability network** — connects sandbox to shared Jaeger/Grafana/Prometheus
2. **OTEL configuration** — sets exporter endpoint and namespace attributes
3. **Volume mounts** — maps worktree code and shared data into containers

### Health Gate (sub-module of Sandbox Manager)

**Purpose:** Polls a health endpoint after sandbox startup until the service is ready or timeout is reached.

**Behavior:**
- HTTP GET to `http://localhost:<health_port>/<health_endpoint>`
- Poll interval: 2 seconds
- Timeout: configurable (default 60s, from infra.toml)
- Success: HTTP 200
- Failure: warning (non-fatal) — services may still be starting

### Observability Manager

**Location:** `src/devops_ai/observability.py`
**Purpose:** Manages the shared observability stack (Jaeger + Grafana + Prometheus) that serves all sandboxes.

**Interface (illustrative):**
```python
def ensure_running() -> None: ...          # start if not already running
def start() -> None: ...                   # start the shared stack
def stop() -> None: ...                    # stop the shared stack
def status() -> ObservabilityStatus: ...   # check health of shared services
def get_endpoints() -> dict[str, str]: ... # return URLs for Jaeger UI, Grafana, etc.
```

**Infrastructure location:** `~/.devops-ai/observability/`

Contains:
- `docker-compose.yml` — generated from template on first run
- Network: `devops-ai-observability` (external Docker network)

**Port range:** Dedicated range that does NOT conflict with ktrdr's ports (ktrdr uses standard ports 16686, 3000, 9090 and offsets up to ~+10). The shared stack uses a separate range (exact ports TBD during implementation, likely 4xxxx range).

**Services:**

| Service | Internal Port | Host Port | Purpose |
|---------|--------------|-----------|---------|
| devops-ai-jaeger | 16686 | TBD (e.g., 46686) | Jaeger UI |
| devops-ai-jaeger | 4317 | TBD (e.g., 44317) | OTLP gRPC receiver |
| devops-ai-grafana | 3000 | TBD (e.g., 43000) | Grafana dashboards |
| devops-ai-prometheus | 9090 | TBD (e.g., 49090) | Prometheus metrics |

**Container names** are prefixed with `devops-ai-` to avoid collision with any project's own containers. The `devops-ai-observability` Docker network allows sandboxes to reach `devops-ai-jaeger:4317` by container name.

**Lifecycle:**
- Started by `kinfra observability up` or auto-started by first `kinfra impl`
- Intended to stay running permanently (lightweight: ~200MB total)
- Stopped explicitly by `kinfra observability down` (for cleanup or troubleshooting)

### Agent-Deck Integration

**Location:** `src/devops_ai/agent_deck.py`
**Purpose:** Optional session management via agent-deck. Checks for availability, manages sessions.

**Interface (illustrative):**
```python
def is_available() -> bool: ...                        # checks PATH for agent-deck
def add_session(title: str, group: str, path: Path) -> None: ...
def remove_session(title: str) -> None: ...
def start_session(title: str) -> None: ...
def send_to_session(title: str, message: str) -> None: ...
```

**Session naming convention:**
- Spec: `spec/<feature>` in group `dev`
- Impl: `<feature>/<milestone>` in group `dev`

### CLI Entry Point

**Location:** `src/devops_ai/cli/main.py`
**Purpose:** Typer app exposing all commands via the `kinfra` entry point.

**Commands:**

| Command | Arguments | What it does |
|---------|-----------|--------------|
| `kinfra init` | (interactive) | Inspect project, generate infra.toml, parameterize compose, setup observability network |
| `kinfra spec <feature>` | feature name | Create spec worktree (no sandbox) |
| `kinfra impl <feature/milestone>` | feature/milestone, `--session` | Create worktree + claim slot + start sandbox + optional agent-deck |
| `kinfra done <name>` | worktree name, `--force` | Stop sandbox + release slot + remove worktree + optional agent-deck cleanup |
| `kinfra worktrees` | (none) | List active worktrees with slot status across all projects |
| `kinfra status` | (none) | Show current sandbox details (from current directory) |
| `kinfra observability up` | (none) | Start shared observability stack |
| `kinfra observability down` | (none) | Stop shared observability stack |
| `kinfra observability status` | (none) | Show shared stack health |

## Data Flow

### `kinfra init` Flow

```
Developer runs: kinfra init
         │
         ▼
┌─ Inspect Project ──────────────────────────┐
│ 1. Find docker-compose*.yml                │
│ 2. Parse services and port mappings        │
│ 3. Detect project name from pyproject.toml │
│    / package.json / .devops-ai/project.md  │
│ 4. Load global registry                    │
│ 5. Identify observability services         │
│    (jaeger, prometheus, grafana)            │
└─────────────┬──────────────────────────────┘
              │
              ▼
┌─ Interactive Setup ────────────────────────┐
│ 6. Confirm project name and prefix         │
│ 7. Confirm app services and their ports    │
│ 8. Note: observability services will be    │
│    provided by shared stack                │
│ 9. Ask for health endpoint                 │
│ 10. Ask which dirs are code vs shared      │
│ 11. Ask which services get code mounts     │
└─────────────┬──────────────────────────────┘
              │
              ▼
┌─ Generate Config + Update Compose ─────────┐
│ 12. Write .devops-ai/infra.toml            │
│ 13. Update docker-compose.yml:             │
│     - Replace hardcoded host ports with    │
│       env vars: "${VAR:-default}:internal" │
│     - Comment out observability services   │
│       (with explanation)                   │
│     - Add comments explaining kinfra usage │
│ 14. Ensure shared observability network    │
│     exists (docker network create)         │
│ 15. Report completion with any warnings    │
└────────────────────────────────────────────┘
```

**Flow Steps (Structured):**

1. Find docker-compose file(s) in project root
2. Parse YAML to extract services and their published port mappings
3. Detect project name from pyproject.toml, package.json, go.mod, or .devops-ai/project.md
4. Load global registry and check for base port proximity with other projects
5. Identify observability services by image name (jaegertracing/*, prom/prometheus, grafana/grafana)
6. Present findings, ask developer to confirm/adjust project name and worktree prefix
7. Present app services (non-observability) with their ports
8. Explain that observability is provided by the shared stack; offer to comment out observability services from compose
9. Ask for health check endpoint (suggest common patterns)
10. Ask which directories contain source code vs shared data
11. Ask which compose services should receive worktree code mounts
12. Write `.devops-ai/infra.toml` with all answers
13. Rewrite docker-compose.yml: parameterize host ports with env vars, comment out observability services, add explanatory comments for coding agents
14. Create Docker network `devops-ai-observability` if it doesn't exist
15. Report completion with warnings about port proximity or other concerns

### `kinfra impl` Flow

```
Developer runs: kinfra impl wellness-reminders/M1
         │
         ▼
┌─ Validate ─────────────────────────────────┐
│ 1. Load infra.toml from current project    │
│ 2. Find milestone file in design docs      │
│ 3. Check worktree doesn't already exist    │
└─────────────┬──────────────────────────────┘
              │
              ▼
┌─ Ensure Observability ─────────────────────┐
│ 4. Check if shared stack is running        │
│ 5. If not: start it automatically          │
└─────────────┬──────────────────────────────┘
              │
              ▼
┌─ Allocate Slot ────────────────────────────┐
│ 6. Load global registry                    │
│ 7. Find next free slot (1-100)             │
│ 8. Compute ports: base + slot_id           │
│ 9. TCP bind test all ports                 │
│ 10. If conflict: try next slot             │
│ 11. If all exhausted: error                │
└─────────────┬──────────────────────────────┘
              │
              ▼
┌─ Create Worktree ──────────────────────────┐
│ 12. git fetch origin main                  │
│ 13. git worktree add <path> -b <branch>    │
└─────────────┬──────────────────────────────┘
              │
              ▼
┌─ Start Sandbox ────────────────────────────┐
│ 14. Create slot dir: ~/.devops-ai/slots/   │
│     <project>-<slot_id>/                   │
│ 15. Claim slot in registry                 │
│ 16. Generate .env.sandbox in slot dir      │
│ 17. Generate docker-compose.override.yml   │
│     in slot dir (code mounts + observ.     │
│     network + OTEL env vars)               │
│ 18. docker compose up -d                   │
│     (-f worktree/compose -f slot/override  │
│      --env-file slot/.env.sandbox)         │
│ 19. Health gate (poll until ready)          │
│ 20. On failure: release slot, keep worktree│
└─────────────┬──────────────────────────────┘
              │
              ▼
┌─ Optional: Agent-Deck ─────────────────────┐
│ 21. If --session and agent-deck available: │
│     a. agent-deck add session              │
│     b. agent-deck session start            │
│     c. agent-deck session send /kmilestone │
└────────────────────────────────────────────┘
```

### `kinfra done` Flow

```
Developer runs: kinfra done wellness-reminders-M1
         │
         ▼
┌─ Find and Validate ───────────────────────┐
│ 1. Find worktree by name (partial match)  │
│ 2. Find slot for this worktree in registry│
│ 3. Check for uncommitted changes          │
│ 4. Check for unpushed commits             │
│ 5. Abort unless --force                   │
└─────────────┬─────────────────────────────┘
              │
              ▼
┌─ Cleanup ─────────────────────────────────┐
│ 6. Stop sandbox: docker compose down      │
│    (from slot dir, referencing worktree   │
│     compose file)                         │
│ 7. Remove slot dir contents               │
│    (.env.sandbox, override.yml)           │
│ 8. Remove slot directory                  │
│ 9. Release slot in registry               │
│ 10. Remove git worktree                   │
│ 11. If agent-deck: remove session         │
└───────────────────────────────────────────┘
```

### `kinfra observability up` Flow

```
Developer runs: kinfra observability up
         │
         ▼
┌─ Setup ───────────────────────────────────┐
│ 1. Check if ~/.devops-ai/observability/   │
│    exists; create if not                  │
│ 2. Generate docker-compose.yml from       │
│    template (if not present or outdated)  │
│ 3. Create Docker network                  │
│    devops-ai-observability (if not exists)│
│ 4. docker compose up -d from              │
│    observability directory                │
│ 5. Health check: Jaeger UI responds       │
│ 6. Report endpoints                       │
└───────────────────────────────────────────┘
```

## State Management

| State | Where | Lifecycle |
|-------|-------|-----------|
| Infrastructure config | `<project>/.devops-ai/infra.toml` | Created by `kinfra init`, read by all commands |
| Parameterized compose | `<project>/docker-compose.yml` | Updated by `kinfra init`, used by `impl`/`done` |
| Global slot registry | `~/.devops-ai/registry.json` | Created on first `impl`, updated on claim/release |
| Slot directory | `~/.devops-ai/slots/<project>-<N>/` | Created by `impl`, removed by `done` |
| Sandbox env file | `<slot_dir>/.env.sandbox` | Created by `impl`, removed by `done` |
| Compose override | `<slot_dir>/docker-compose.override.yml` | Created by `impl`, removed by `done` |
| Docker containers | Docker daemon | Started by `impl`, stopped by `done`, scoped by `COMPOSE_PROJECT_NAME` |
| Docker network | `devops-ai-observability` | Created by `init` or `observability up`, persistent |
| Git worktrees | `<project>/../<prefix>-{spec,impl}-*` | Created by `spec`/`impl`, removed by `done` |
| Shared observability | `~/.devops-ai/observability/` | Started by `observability up` or auto-started by first `impl`, always running |

## Error Handling

| Situation | Behavior |
|-----------|----------|
| No infra.toml found | `spec` works (worktree only). `impl` with Docker: error with "Run `kinfra init` first" |
| No compose file found | Error: "Docker Compose file not found at `<path>`. Check compose_file in infra.toml" |
| All 100 slots occupied | Error: "No slots available (1-100 all claimed). Run `kinfra worktrees` to see active slots." |
| Port conflict (TCP bind) | Skip slot, try next. If all tried: error with specific conflict details |
| Docker compose fails to start | Release slot, keep worktree. Error: "Sandbox failed to start. Worktree preserved at `<path>`." |
| Health gate timeout | Warning (not fatal): "Health check timed out after `<N>`s. Services may still be starting." |
| Worktree has uncommitted changes | `done` aborts: "Uncommitted changes detected. Use `--force` to override." |
| Worktree has unpushed commits | `done` aborts: "Unpushed commits detected. Use `--force` to override." |
| agent-deck not installed | Skip silently, note in output: "agent-deck not found, skipping session management" |
| Worktree already exists | Error: "Worktree already exists at `<path>`" |
| Milestone file not found | Error: "No milestone file matching `<pattern>` in design docs" |
| Shared observability not running | `impl` auto-starts it. Warning: "Starting shared observability stack..." |
| Registry file corrupted | Attempt recovery from backup; if none, warn and create fresh registry |
| Docker network missing | Recreate `devops-ai-observability` network automatically |

## Integration Points

| Component | Current State | Change Needed |
|-----------|---------------|---------------|
| devops-ai project structure | Pure markdown skills, no Python | Add `pyproject.toml`, `src/devops_ai/` package |
| `install.sh` | Symlinks skills only | Add `uv tool install -e .` step |
| kmilestone/ktask skills | Reference project.md for test/quality commands | Can optionally read infra.toml for health/status info |
| Project docker-compose | Hardcoded host ports | `kinfra init` parameterizes with env vars + adds comments |
| Project docker-compose | May include observability services | `kinfra init` offers to comment them out (shared stack provides them) |
| ktrdr | Has its own kinfra CLI and sandbox system | **No changes.** ktrdr's ports are avoided by devops-ai's shared stack port range. TCP bind test catches any runtime conflicts. |

## .devops-ai/infra.toml Format

### khealth (simple project — 12 lines)

```toml
[project]
name = "khealth"
prefix = "khealth"

[sandbox]
compose_file = "docker-compose.yml"

[sandbox.health]
endpoint = "/api/v1/health"
port_var = "KHEALTH_API_PORT"

[sandbox.ports]
KHEALTH_API_PORT = 8080
```

### ktrdr-style complex project (22 lines)

```toml
[project]
name = "ktrdr"
prefix = "ktrdr"

[sandbox]
compose_file = "docker-compose.sandbox.yml"

[sandbox.health]
endpoint = "/api/v1/health"
port_var = "KTRDR_API_PORT"
timeout = 120

[sandbox.ports]
KTRDR_API_PORT = 8000
KTRDR_DB_PORT = 5432
KTRDR_WORKER_PORT_1 = 5003
KTRDR_WORKER_PORT_2 = 5004
KTRDR_WORKER_PORT_3 = 5005
KTRDR_WORKER_PORT_4 = 5006

[sandbox.mounts]
code = ["ktrdr/", "research_agents/", "tests/", "config/:ro"]
code_targets = ["backend", "backtest-worker", "training-worker"]
shared = ["data/", "models/", "strategies/"]
shared_targets = ["backend", "backtest-worker", "training-worker"]
```

## Docker Compose Parameterization

What `kinfra init` does to the project's compose file:

**Before:**
```yaml
services:
  wellness-agent:
    build: .
    ports:
      - "8080:8080"
    depends_on:
      - jaeger

  jaeger:
    image: jaegertracing/jaeger:latest
    ports:
      - "16686:16686"
      - "4317:4317"
    environment:
      - COLLECTOR_OTLP_ENABLED=true
```

**After:**
```yaml
# =============================================================================
# kinfra-managed Docker Compose file
# =============================================================================
# Host ports use environment variables for sandbox isolation. Each sandbox slot
# offsets ports by its slot number. Default values (after :-) are the base ports
# for running without kinfra. See .devops-ai/infra.toml for configuration.
#
# To run without kinfra: docker compose up -d (defaults apply)
# To run in sandbox:     kinfra impl <feature/milestone>
# =============================================================================

services:
  wellness-agent:
    build: .
    ports:
      - "${KHEALTH_API_PORT:-8080}:8080"
    # Note: observability (Jaeger/Grafana/Prometheus) is provided by kinfra's
    # shared stack. This service connects to it via the devops-ai-observability
    # network (added automatically by kinfra when running in a sandbox).

  # -------------------------------------------------------------------------
  # Observability services below are commented out because kinfra provides
  # a shared observability stack. To use standalone (without kinfra), uncomment.
  # -------------------------------------------------------------------------
  # jaeger:
  #   image: jaegertracing/jaeger:latest
  #   ports:
  #     - "16686:16686"
  #     - "4317:4317"
  #   environment:
  #     - COLLECTOR_OTLP_ENABLED=true
```

## Shared Observability Stack

### Network Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│  Docker Network: devops-ai-observability                        │
│                                                                 │
│  ┌─────────────────┐  ┌────────────────┐  ┌─────────────────┐  │
│  │ devops-ai-jaeger│  │devops-ai-grafana│ │devops-ai-prom   │  │
│  │                 │  │                │  │                 │  │
│  │ OTLP :4317      │  │ UI   :3000     │  │ HTTP :9090      │  │
│  │ UI   :16686     │  │                │  │                 │  │
│  └────────┬────────┘  └───────┬────────┘  └────────┬────────┘  │
│           │                   │                    │            │
│  ┌────────┴───────────────────┴────────────────────┴─────────┐  │
│  │                    Shared Network                         │  │
│  └───────────────────────┬───────────────────────────────────┘  │
│                          │                                      │
│  ┌───────────┐  ┌───────┴───┐  ┌───────────┐                   │
│  │ khealth   │  │ project-B │  │ project-C │ (sandbox apps)    │
│  │ slot-1    │  │ slot-2    │  │ slot-5    │                   │
│  └───────────┘  └───────────┘  └───────────┘                   │
└─────────────────────────────────────────────────────────────────┘

Host port mapping (does NOT conflict with ktrdr):
  devops-ai-jaeger   → host:46686 (UI), host:44317 (OTLP gRPC)
  devops-ai-grafana  → host:43000
  devops-ai-prom     → host:49090
```

### OTEL Namespace Strategy

Each sandbox gets a unique namespace via OTEL resource attributes, set automatically in the override file:

```
OTEL_RESOURCE_ATTRIBUTES=service.namespace=<project>-slot-<N>
```

In Jaeger UI, services appear as:
- `khealth-slot-1/wellness-agent`
- `khealth-slot-3/wellness-agent`
- `projectB-slot-2/api-server`

Filtering by `service.namespace` isolates one sandbox's traces.

### Template

**Location:** `templates/observability/docker-compose.yml` (in devops-ai repo)

Copied to `~/.devops-ai/observability/docker-compose.yml` on first use. Contains Jaeger all-in-one, Grafana, and Prometheus with OTLP receiver enabled.

## Verification Approach

| Component | How to Verify |
|-----------|---------------|
| Config Loader | Unit tests: parse valid/invalid TOML, missing fields, defaults, find_project_root walk-up |
| Worktree Manager | Unit tests: naming conventions, branch names. Integration: actual git worktree add/remove |
| Port Allocator | Unit tests: offset math, conflict detection with mocked registry. Integration: TCP bind tests |
| Slot Registry | Unit tests: allocate, claim, release, persistence, stale cleanup. Edge: concurrent access |
| Sandbox Manager | Unit tests: env file content, override YAML content. Integration: docker compose up/down |
| Health Gate | Unit tests: polling logic, timeout handling. Integration: real HTTP endpoint |
| Observability Manager | Unit tests: template generation, network creation. Integration: docker compose lifecycle |
| Agent-Deck | Unit tests: command string generation. Integration: requires agent-deck installed |
| CLI commands | Integration tests: full `init` → `spec` → `impl` → `done` cycle on a test project |
| kworktree skill | Manual: invoke via Claude Code, verify correct kinfra commands issued |

## Implementation Planning Summary

### New Components to Create

| Component | Location | Purpose |
|-----------|----------|---------|
| pyproject.toml | `devops-ai/pyproject.toml` | Package definition with `kinfra` entry point, dependencies (typer, tomli, pyyaml, rich) |
| Package init | `src/devops_ai/__init__.py` | Package marker |
| CLI main | `src/devops_ai/cli/main.py` | Typer app with all commands |
| CLI init | `src/devops_ai/cli/init_cmd.py` | `kinfra init` — project inspection + config generation + compose parameterization |
| CLI spec | `src/devops_ai/cli/spec.py` | `kinfra spec` — spec worktree creation |
| CLI impl | `src/devops_ai/cli/impl.py` | `kinfra impl` — impl worktree + sandbox |
| CLI done | `src/devops_ai/cli/done.py` | `kinfra done` — cleanup |
| CLI worktrees | `src/devops_ai/cli/worktrees.py` | `kinfra worktrees` — list active worktrees |
| CLI status | `src/devops_ai/cli/status.py` | `kinfra status` — current sandbox details |
| CLI observability | `src/devops_ai/cli/observability.py` | `kinfra observability up/down/status` |
| Config loader | `src/devops_ai/config.py` | infra.toml parsing and validation |
| Worktree manager | `src/devops_ai/worktree.py` | Git worktree operations |
| Slot registry | `src/devops_ai/registry.py` | Global slot tracking with JSON persistence |
| Port allocator | `src/devops_ai/ports.py` | Port offset computation + TCP bind conflict detection |
| Sandbox manager | `src/devops_ai/sandbox.py` | Compose override/env generation, Docker lifecycle, health gate |
| Observability manager | `src/devops_ai/observability.py` | Shared stack lifecycle |
| Agent-deck integration | `src/devops_ai/agent_deck.py` | Optional session management |
| kworktree skill | `skills/kworktree/SKILL.md` | Conversational wrapper for kinfra commands |
| Observability template | `templates/observability/docker-compose.yml` | Jaeger + Grafana + Prometheus compose |

### Existing Components to Modify

| Component | Location | Changes Required |
|-----------|----------|------------------|
| install.sh | `devops-ai/install.sh` | Add `uv tool install -e .` step after symlinks |
| ROADMAP.md | `devops-ai/ROADMAP.md` | Move kinfra items from "Future" to "In Progress" |

### Files to Delete

None.
